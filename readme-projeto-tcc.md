# üçé Self-Checkout Fruit Detection System: A Deep Dive

Oi Felipe!!!! Seguem algumas dicas

*Este documento detalha o projeto de um sistema de detec√ß√£o de frutas para terminais de autoatendimento, expandindo a documenta√ß√£o inicial com justificativas t√©cnicas, estrat√©gias de dados e pipeline de produ√ß√£o.*

---

## 1. Desafio de Neg√≥cio

O objetivo √© desenvolver um **terminal de self-checkout** inteligente capaz de identificar automaticamente as frutas mais comuns ‚Äî **banana, ma√ß√£ e uva** ‚Äî em tempo real. O sistema precisa ser robusto o suficiente para funcionar em m√∫ltiplos cen√°rios, como quando o cliente:

- Coloca a fruta solta sobre a balan√ßa.
- Pesa as frutas dentro de um saco pl√°stico (transparente ou opaco).
- Segura a fruta com os dedos em frente √† c√¢mera.

### üìä Metas de Performance

O sucesso do projeto ser√° medido por m√©tricas rigorosas de precis√£o e lat√™ncia, essenciais para uma experi√™ncia de usu√°rio fluida e confi√°vel.


| M√©trica            | Valor Alvo | Justificativa                                                                                 |
| --------------------- | ------------ | ----------------------------------------------------------------------------------------------- |
| **Precis√£o Top-1** | ‚â• 95%     | Garante que a primeira predi√ß√£o do sistema seja a correta na grande maioria das vezes.      |
| **mAP@0.5**         | ‚â• 0.90    | Avalia a capacidade do modelo de localizar corretamente os objetos (IoU > 50%).               |
| **mAP@0.5:0.95**    | ‚â• 0.65    | M√©trica mais rigorosa que avalia a precis√£o da localiza√ß√£o em diferentes limiares de IoU. |
| **Lat√™ncia**       | < 100ms    | Essencial para uma resposta em tempo real em hardware embarcado de baixo custo.               |

---

## 2. Escopo e Varia√ß√µes Suportadas

Para garantir que o modelo seja robusto no mundo real, ele ser√° treinado para lidar com uma vasta gama de varia√ß√µes.

#### Subvariedades de Frutas

- **Ma√ß√£**: Gala, Fuji, Verde
- **Uva**: Roxa, Verde
- **Banana**: Nanica, Prata, Banana-ma√ß√£

#### Condi√ß√µes de Captura de Imagem


| Aspecto            | Varia√ß√µes                                      |
| -------------------- | -------------------------------------------------- |
| **Quantidade**     | `one`, `few` (2-3), `many` (4+)                  |
| **Embalagem**      | `none`, `plastic_bag`                            |
| **Transpar√™ncia** | `transparent`, `semi_transparent`, `opaque`      |
| **Intera√ß√£o**    | `none`, `held_by_fingers` (oclus√£o parcial)     |
| **Ilumina√ß√£o**   | `even`, `shadowed`, `glare` (reflexo)            |
| **√Çngulo**        | `top_down`, `slightly_tilted`                    |
| **Superf√≠cie**    | `black_scale`, `wood_surface`, `plastic_surface` |
| **Qualidade**      | `sharp`, `slightly_blurry`, `noisy`              |

---

## 3. Stack Tecnol√≥gico e Justificativas

A escolha da tecnologia foi guiada pela necessidade de performance em tempo real, baixo custo de hardware e um ciclo de desenvolvimento r√°pido.


| Componente             | Tecnologia                                  |
| ------------------------ | --------------------------------------------- |
| **Modelo Base**        | YOLOv8n (Ultralytics)                       |
| **Gera√ß√£o de Dados** | Gemini / DALL¬∑E 3                          |
| **Anota√ß√£o**         | Segment Anything (SAM) + YOLO pr√©-treinado |
| **Augmentation**       | Albumentations                              |
| **Treinamento**        | Google Colab / GPU local (PyTorch)          |
| **Deploy**             | Python + OpenCV + ONNX-Runtime              |

### Por que YOLOv8n?

A escolha do YOLOv8n (nano) n√£o foi acidental. Ele oferece a melhor combina√ß√£o de velocidade, tamanho e precis√£o para dispositivos de borda (*edge devices*).


| Crit√©rio                  | Vantagem do YOLOv8n                                                      |
| ---------------------------- | -------------------------------------------------------------------------- |
| **Tempo Real**             | >30 FPS em hardware modesto, identificando frutas instantaneamente.      |
| **Tamanho Reduzido**       | ~6 MB, ideal para a mem√≥ria limitada de um dispositivo embarcado.       |
| **Detec√ß√£o Multiobjeto** | Localiza m√∫ltiplas frutas e tipos de fruta na mesma imagem.             |
| **Pipeline Simples**       | A framework Ultralytics unifica treino, valida√ß√£o e exporta√ß√£o.      |
| **Escalabilidade**         | Permite migrar para modelos maiores (YOLOv8s/m/l) sem alterar o dataset. |

#### Alternativas Consideradas (e por que foram descartadas)


| Modelo                        | Limita√ß√£o no nosso caso                                                                                                                                                                   |
| ------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **EfficientNet, MobileNetV3** | S√£o modelos de**classifica√ß√£o**, n√£o **detec√ß√£o**. N√£o fornecem as caixas delimitadoras (*bounding boxes*) necess√°rias para localizar m√∫ltiplas frutas.                            |
| **Segment Anything (SAM)**    | √â uma ferramenta fant√°stica para**segmenta√ß√£o**, mas √© computacionalmente pesada (~200 MB) e lenta para infer√™ncia em tempo real. Usaremos no pipeline de anota√ß√£o, n√£o no deploy. |
| **YOLOv5/7**                  | YOLOv8 possui uma arquitetura mais limpa, √© mais preciso e mantido ativamente pela Ultralytics.                                                                                            |

---

## 4. Estrat√©gia de Dados: Gera√ß√£o Sint√©tica

A anota√ß√£o manual de milhares de imagens √© o maior gargalo em projetos de vis√£o computacional. Para contornar isso, adotamos uma **estrat√©gia de dados sint√©ticos**, que nos permite criar um dataset grande, diverso e perfeitamente balanceado a um custo muito baixo.

O fluxo √© o seguinte:

1. **Definir Cen√°rios**: Criar um arquivo CSV com ~500 combina√ß√µes das varia√ß√µes descritas na Se√ß√£o 2.
2. **Gerar Prompts**: Um script "Prompt-Factory" converte cada linha do CSV em um prompt detalhado para um modelo de gera√ß√£o de imagem.
3. **Gerar Imagens**: O prompt √© enviado ao Gemini ou DALL¬∑E 3 para criar a imagem sint√©tica.
4. **Auto-Anota√ß√£o**: As imagens geradas s√£o automaticamente anotadas para criar as *bounding boxes*. basta colocar no codigo!
5. Note que nao basta simplesmente colocar a imagem e treinar. Tem que colocar uma anotacao por aimagem. GenAI faz isso .

### A. Schema do CSV (uma linha = uma imagem)


| Coluna             | Valores Poss√≠veis                               |
| -------------------- | -------------------------------------------------- |
| `fruit`            | `banana`, `apple`, `grape`                       |
| `subtype`          | Nanica, Prata / Gala, Fuji / Roxa, Verde         |
| `quantity`         | `one`, `few`, `many`                             |
| `container_type`   | `none`, `plastic_bag`                            |
| `bag_transparency` | `transparent`, `semi_transparent`, `opaque`      |
| `lighting`         | `even`, `shadowed`, `glare`                      |
| `angle`            | `top_down`, `slightly_tilted`                    |
| `interaction`      | `none`, `held_by_fingers`                        |
| `surface_type`     | `black_scale`, `wood_surface`, `plastic_surface` |
| `camera_quality`   | `sharp`, `slightly_blurry`, `noisy`              |

### B. Prompt-Factory

Um LLM recebe a linha do CSV como um JSON e a transforma em uma descri√ß√£o em ingl√™s fluente.

```prompt
Given a JSON with attributes, write a fluent English prompt describing 
the scene so an image generator can draw it. Mention fruit type + subtype 
+ color, container + transparency, lighting, camera angle, surface, 
fingers if present, quantity, and image quality. Avoid column names.
```

### C. Anota√ß√£o R√°pida com IA

Em vez de desenhar caixas manualmente, usamos um fluxo de IA:

1. **Auto-Segmentar com SAM**: O modelo Segment Anything (SAM) gera m√°scaras de segmenta√ß√£o de alta precis√£o para cada fruta na imagem.
2. **Converter para Bounding Box**: A m√°scara √© convertida para uma *bounding box* no formato YOLO.
3. **Bootstrap com YOLO pr√©-treinado**: Alternativamente, um modelo YOLOv8 treinado no dataset COCO j√° sabe o que √© "banana" e "apple" e pode gerar os r√≥tulos iniciais.
4. **Revis√£o Manual (10-20%)**: Apenas uma pequena fra√ß√£o do dataset √© revisada manualmente para garantir a qualidade e consist√™ncia das anota√ß√µes.

Este processo reduz o esfor√ßo de anota√ß√£o em mais de 90%.

---

## 5. Pipeline de Treinamento e Valida√ß√£o

### Estrutura de Diret√≥rios

O dataset deve seguir a estrutura padr√£o exigida pelo YOLO.

```
dataset/
‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îî‚îÄ‚îÄ val/
‚îú‚îÄ‚îÄ labels/
‚îÇ   ‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îî‚îÄ‚îÄ val/
‚îî‚îÄ‚îÄ data.yaml
```

### Configura√ß√£o `data.yaml`

Este arquivo aponta para os dados de treino/valida√ß√£o e define as classes do projeto.

```yaml
path: ./dataset
train: images/train
val: images/val
nc: 3
names: ['banana', 'apple', 'grape']
```

### Augmentation de Imagens

Para aumentar a variabilidade do dataset, aplicamos transforma√ß√µes em tempo real durante o treinamento com `Albumentations`.

```python
import albumentations as A

augmentation_pipeline = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.2),
    A.Rotate(limit=15, p=0.3),
    A.GaussNoise(p=0.15),
    A.MotionBlur(p=0.15),
])
```

### Comando de Treinamento

O treinamento √© iniciado com um √∫nico comando.

```bash
yolo detect train model=yolov8n.pt data=data.yaml epochs=50 imgsz=640
```

### Valida√ß√£o com Dados Reais

Ap√≥s o treino com dados sint√©ticos, o modelo √© validado contra um pequeno conjunto de **100 fotos reais**, coletadas e anotadas manualmente. Essas imagens reais s√£o ent√£o incorporadas ao dataset para um ciclo de refinamento.

---

## 6. Deploy e Ciclo de Vida em Produ√ß√£o

### Export do Modelo

O modelo treinado (um arquivo `.pt` do PyTorch) √© exportado para o formato ONNX (Open Neural Network Exchange), que √© otimizado para infer√™ncia de alta performance em qualquer plataforma.

```bash
yolo export model=runs/detect/train/weights/best.pt format=onnx
```

### Infer√™ncia e Monitoramento

- **Runtime**: A aplica√ß√£o final utiliza Python com `ONNX-Runtime` para carregar o modelo e `OpenCV` para capturar os frames da c√¢mera.
- **Fallback**: Se a confian√ßa da predi√ß√£o for muito baixa (ex: < 0.3), o sistema pode solicitar interven√ß√£o humana.
- **Logging**: Cada predi√ß√£o √© registrada em um log JSON estruturado para an√°lise futura.
  ```json
  {
    "timestamp": "2024-01-01T12:00:00Z",
    "fruit_pred": "banana",
    "confidence": 0.95,
    "bbox": [x, y, w, h]
  }
  ```
- **Retreinamento Cont√≠nuo**: Os logs s√£o analisados semanalmente para identificar casos de falha (edge cases). Esses casos s√£o coletados, anotados e incorporados ao dataset para um retreinamento mensal, garantindo que o modelo melhore continuamente.

---

## 7. Cronograma Estimado


| Fase              | Dura√ß√£o | Tarefas Principais                                               |
| ------------------- | ----------- | ------------------------------------------------------------------ |
| **Semanas 1-2**   | 2 semanas | Setup do ambiente, Gera√ß√£o do CSV, Script Prompt-Factory.      |
| **Semanas 3-4**   | 2 semanas | Gera√ß√£o e armazenamento das imagens sint√©ticas.               |
| **Semanas 5-6**   | 2 semanas | Pipeline de anota√ß√£o autom√°tica e revis√£o manual.            |
| **Semanas 7-8**   | 2 semanas | Treinamento do modelo inicial e an√°lise de resultados.          |
| **Semanas 9-10**  | 2 semanas | Coleta de dados reais, refinamento e retreinamento.              |
| **Semanas 11-12** | 2 semanas | Export do modelo, testes de integra√ß√£o e documenta√ß√£o final. |

---

## 8. Refer√™ncias

- **YOLOv8**: [Ultralytics Documentation](https://docs.ultralytics.com/)
- **SAM**: [Segment Anything Model](https://segment-anything.com/)
- **Albumentations**: [Documentation](https://albumentations.ai/)
- **ONNX**: [ONNX Runtime Documentation](https://onnxruntime.ai/)
